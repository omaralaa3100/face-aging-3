{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LATS_demo.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uubo7PsvxQ"
      },
      "source": [
        "!git clone https://github.com/royorel/Lifespan_Age_Transformation_Synthesis\n",
        "%cd Lifespan_Age_Transformation_Synthesis/\n",
        "!pip3 install -r requirements.txt\n",
        "!pip install torch\n",
        "\n",
        "!python download_models.py\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from options.test_options import TestOptions\n",
        "from data.data_loader import CreateDataLoader\n",
        "from models.models import create_model\n",
        "import util.util as util\n",
        "from util.visualizer import Visualizer\n",
        "\n",
        "opt = TestOptions().parse(save=False)\n",
        "opt.display_id = 0  # do not launch visdom\n",
        "opt.nThreads = 1  # test code only supports nThreads = 1\n",
        "opt.batchSize = 1  # test code only supports batchSize = 1\n",
        "opt.serial_batches = True  # no shuffle\n",
        "opt.no_flip = True  # no flip\n",
        "opt.in_the_wild = True  # This triggers preprocessing of in the wild images in the dataloader\n",
        "opt.traverse = True  # This tells the model to traverse the latent space between anchor classes\n",
        "opt.interp_step = 0.05  # this controls the number of images to interpolate between anchor classes\n",
        "\n",
        "data_loader = CreateDataLoader(opt)\n",
        "dataset = data_loader.load_data()\n",
        "visualizer = Visualizer(opt)\n",
        "\n",
        "opt.name = 'males_model'  # change to 'females_model' if you're trying the code on a female image\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    img_path = filename\n",
        "    print('User uploaded file \"{name}\"'.format(name=filename))\n",
        "\n",
        "data = dataset.dataset.get_item_from_path(img_path)\n",
        "visuals = model.inference(data)\n",
        "os.makedirs('results', exist_ok=True)\n",
        "out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.mp4')\n",
        "visualizer.make_video(visuals, out_path)\n",
        "\n",
        "# Extract frames from the video and save as images\n",
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(out_path)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "os.makedirs('frames', exist_ok=True)\n",
        "for i in range(frame_count):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_path = os.path.join('frames', f'frame_{i}.png')\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Zip the frames for easier downloading\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive('frames_archive', 'zip', 'frames')\n",
        "\n",
        "# Download the zip file containing frames\n",
        "files.download('frames_archive.zip')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}